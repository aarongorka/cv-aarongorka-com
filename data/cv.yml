personal:
  name: "Aaron Gorka"
  url: https://aarongorka.com
  summary: "Aaron is a specialist in cloud-native, CI/CD and DevOps transformation. He is experienced in solutions architecture and consulting for cloud projects. Aaron is self-driven and highly motivated."
  profiles:
    - url: https://github.com/aarongorka
    - url: https://linkedin.com/in/aarongorka
skills:
  - name: Cloud
    keywords: ["AWS", "CloudFormation", "Terraform", "CDK", "Pulumi"]
  - name: Continous Delivery
    keywords: ["Github Actions", "Buildkite", "Gitlab", "Codefresh", "CircleCI"]
  - name: Docker & Serverless
    keywords: ["Kubernetes", "Docker", "EKS", "ECS", "Fargate", "Lambda"]
  - name: "Development"
    keywords: ["Python", "Typescript (Javascript, Nodejs)", "Bash", "Testing"]
  - name: "Linux"
    keywords: ["Networking", "Security", "System administration", "Automation"]
  - name: "Soft skills"
    keywords: ["Consulting", "Delivery", "Project management"]
work:
  - startDate: Feb 2024
    endDate: August 2025
    name: Nearmap
    position: Principal DevOps Engineer
    summary: |
      Acting team lead/principal for the core platform team.

      Technologies used include AWS, EKS, Terraform, Helm, GitLab, GitHub Actions, Prometheus and Loki.

      #### EKS cluster scaling

      I was brought in to assist Nearmap with some issues they were having scaling their EKS cluster beyond 3,000 nodes.

      After optimisation, we could run at least **9,000 GPU nodes**. A few of the (many) optimisations I put in:

        * A >10x reduction in timeseries metric data without any loss of actual monitoring capabilities. Prior to optimisation, the Amazon Managed Prometheus service would hit over 30 million series (the soft limit) with no sign of stopping. After optimisation, it did not exceed 10 million (even with several times more nodes and many more copmonents being monitored). This was achieved with analysis of metrics via PromQL, Grafana dashboard JSON dumps, followed by extensive Prometheus relabel rules to drop any unneeded metrics. The Opentelemetry Collectors were also optimised initially by sharding the scraping across multiple pods to avoid throughput bottlenecks and later by implementing target allocator with Prometheus Operator-compatible CRDs.
        * IP address optimisation via AWS VPC CNI "Custom Networking" a.k.a. secondary subnets. By implementing secondary CIDR ranges using CGNAT IP address space to each EKS VPC, I increased the limit of running pods from 40,000 to 325,000 pods. Additionally, I sharded the VPC CNI daemonsets so that the warm IP address configuration could be optimised for GPU nodes (which only had 1 running workload for cost optimisation reasons) and also configured all the daemonsets to use host networking - reducing the count of 10 IP addresses required per node to just 2.
        * Bringing down the deployment lead time from multi-day to 1 hour. With so many optimisations needed, the time taken by existing change process requiring PRs to over 10 repositories became the main bottleneck (not to mention the amount of code drift). To remediate this, I took the scattered EKS Terraform code and consolidated each separate root module in to a single root module using Terraform Workspaces. This was done without any downtime or loss of code change history. I also implemented a single CI/CD pipeline with Python system tests and approval stages for production. After, changes became a single PR required and all drift between clusters was remediated as a nice side-effect.
        * The creation of 20+ (actively in-use) dashboards for the various components in the EKS platform, as well as a library of alerts (also currently in-use).
        * Optimising each of the components in the cluster to reduce control plane load. For example, configuring Fluentbit to query the local kubelet for pod metadata instead of the control plane, or configuring Opentelemetry Collector to scrape components directly instead of being proxied through the control plane.

      #### Grafana Loki logging platform

        * Designed, wrote Terraform code for and deployed a production-ready instance of Loki to replace an aging Graylog server
        * Designed for multi-tenancy and segregation between multiple environments

      #### Team leadership

        * Stood in to run team rituals while a full-time lead was being hired
        * Provided expert advice and guidance throughout my engagement
        * Mentored juniors
        * Uplifting team standards with the introduction of decision logs, commit guidelines, pre-commit linting, etc.

      #### Other

        * Rearchitecture IAM/RBAC to effective team-based structure
        * Migrated and centralised alert management to Opsgenie, integration with CloudWatch, Prometheus, Loki, Lambdas, Nagios and others
        * Network optimisation project; investigation/planning/design/support for the implementation of AWS Transit Gateway across all VPCs
        * Strategy and implementation of GitHub Actions (self-hosted runners) to replace a self-managed GitLab server
  - startDate: Aug 2018
    endDate: Feb 2024
    name: CMD Solutions (Mantel Group)
    position: Lead Consultant
    summary: |
      CMD Solutions is an AWS partner that provides consulting services. While at CMD, I acted as a lead consultant on client engagements over a ~6 year period. The full list of clients I worked with is too numerous to list here, but some of the projects I'm most proud of are:

      #### Kasada

      [Kasada](https://www.kasada.io/) is a bot mitigation platform that protects a large number of household brand names in Australia and globally (REA, Crocs, Sportsbet, Hyatt, Officeworks and more). The technology stack used included Pulumi, Buildkite, EC2 and EKS.

      ##### CI/CD

      My biggest contribution to Kasada was uplifting their software development lifecycle for their core application from a multi-month release cycle to under a day (commit to production). While it was not the main directive we were brought in for, I proposed it as something that I felt the business could benefit from.

      Implementing this started with interviewing users to understand the reasons the current system existed in the way it did and what the perceived pain points were. Consulting with the product owner, I came up with a SDLC architecture using trunk-based development with short-lived feature branches with progressive rollouts to environments and customers. After this was approved, I worked on preparing the application for automated deployments. This included some foundational work in preparing Buildkite runners and cross-account capabilities.

      Once the technology was in the right state, I worked with the product owner to gradually move all customers to a recent version, and cut them over to the new deployment pipeline - without interrupting any ongoing development work. This took months, but as we added improvements and proved the benefits of releasing continuously, we gradually built trust both internally and externally.

      The ability to release frequently ended up being crucial in Kasada landing their biggest customer to date.

      ##### Scale

      Kasada scaled rapidly in the two years I worked there. Some of the more interesting problems we faced:

        * Hitting the 2,000 target limit on an ALB's Target Group
        * EC2 instance cost effectiveness by migrating to spot arm64 instances
        * Mitigating the limitations of a single-threaded application on multi-core instances
        * Improving scaling to cope with massively spikey traffic patterns
        * Scaling out a Prometheus-based observability system to cope with thousands of servers while maintaining a 15 second scrape interval by leveraging [recording rules](https://prometheus.io/docs/prometheus/latest/configuration/recording_rules/) and multi-tier [federation](https://prometheus.io/docs/prometheus/latest/federation/).

      ##### Log centralisation with Elastic Cloud

      One of the pain points Kasada faced was that production logs were delivered to S3, and for engineers to debug, they needed to download them from S3 and locally parse them with CLI tools. This was time-consuming and lacked any collaborative functionality.

      To combat this, I designed and implemented a logging aggregation platform using Elastic Cloud to host and visualise logs, and [Fluentbit/Fluentd](https://aarongorka.com/blog/why-we-chose-fluentd-over-fluent-bit/) to parse and ship logs. By completion of the engagement, the Elastic Cloud cluster was storing over 20TiB of logs.

      ##### SOC2 and PCI DSS

      To provide services to companies with strict security requirements, Kasada needed to be SOC2 and PCI DSS certified. I worked to ensure that any requirements on the platform side were met.

      ##### EKS microservices platform

      Finally, the main part of work we were brought in to do: designing and implementing Kasada's Kubernetes platform: see the [case study](https://www.cmdsolutions.com.au/case-studies/kasada-modernizes-for-faster-velocity-and-scaling-on-aws/) and [article from Amazon](https://aws.amazon.com/solutions/case-studies/kasada/).

      Another notable aspect of this platform was that it was built from the ground-up to deploy to production with zero manual intervention after a pull request was approved and merged. The core functionalities of the platform were tested after deployment to ensure they remained functional after changes were released: for example, a specific log event was emitted and then queried from the central logging platfrom to ensure that we hadn't broken log shipping. This was all performed automatically.

      #### Vodafone Hutchison Australia (TPG)

      At Vodafone I worked as an AWS Architect on the www.vodafone.com.au website refresh.

      Technologies I worked with include a polarising mix of modern Serverless applications (Next.js) and traditional EC2-based Java applications.

      In this role, I was involved in:

        * Participating in architecture workshops
        * Advising/coordinating teams on all aspects of cloud infrastructure
        * Upskilling the infrastructure team in cloud-native and Python best practices
        * Writing out foundational code examples/templates
        * Doing whatever needed to be done to get the project across the line

      #### Zip Money

        * EKS platform design & build for the new [Amazon Australia partnership](https://www.reuters.com/article/zip-co-deal-amazoncom/amazon-adds-zip-cos-buy-now-pay-later-platform-to-its-australia-website-idUKL3N27M5AZ)
        * CI/CD processes, implementation and culture
        * [Developer skill uplift](https://slides.aarongorka.com/performance-testing-with-taurus/)
        * Go-live Kubernetes support
        * Terraform IaC, GitLab CI/CD

      Other notable projects include Finder, BPay, Equifax, Fox Sports, Bravura and ANZ.
  - startDate: Aug 2017
    endDate: Aug 2018
    name: amaysim
    position: Senior DevOps Engineer
    summary: |
        * Championed DevOps culture in development teams
        * Migrated applications from Rancher to [AWS ECS](https://aarongorka.com/blog/ecs-autoscaling-tips/)
        * Modernised legacy development practices: [pipeline-based CI/CD workflows](https://amaysim.engineering/auto-scaling-build-agents-for-gocdtags-a10f12d5b77c), trunk-based development, immutable artifacts
  - startDate: Feb 2017
    endDate: Jul 2017
    name: Domain Group
    position: DevOps Engineer
    summary: |
      * Building AWS infrastructure and CI/CD pipelines
      * Maintenance and reliability engineering for high-traffic websites including https://domain.com.au
      * Designed and built monitoring platform, [highly useful](http://tech.domain.com.au/2017/05/detecting-memory-issues-with-dotnet-core-applications/) for development teams
      * Delivered solution architecture for rewrite of https://www.mydesktop.com.au
  - startDate: 2015
    endDate: 2017
    name: TAL
    position: System Monitoring Specialist
    summary: |
      * Administrated Linux servers and applications
      * Collaborated with developers, DBAs, application support and infrastructure support to deliver accurate metrics to management
  - startDate: 2013
    endDate: 2015
    name: KU Children's Services
    position: Level 2/3 Support Technician
    summary: |
      Providing support on everything IT-related to ensure business continuity.
certificate:
  - grantDate: 2019
    name: AWS Certified Advanced Networking - Specality
    website: Amazon Web Services
  - grantDate: 2019
    name: AWS Certified Big Data - Speciality
    website: Amazon Web Services
  - grantDate: 2019
    name: AWS Certified Cloud Practitioner
    website: Amazon Web Services
  - grantDate: 2018
    name: AWS Certified Security - Speciality
    website: Amazon Web Services
  - grantDate: 2017
    name: AWS Certified DevOps Engineer - Professional
    website: Amazon Web Services
  - grantDate: 2017
    name: AWS Certified Solutions Architect - Professional
    website: Amazon Web Services
  - grantDate: 2017
    name: AWS Certified SysOps Administrator - Associate
    website: Amazon Web Services
  - grantDate: 2017
    name: AWS Certified Developer - Associate
    website: Amazon Web Services
  - grantDate: 2016
    name: AWS Certified Solutions Architect - Associate
    website: Amazon Web Services
  - grantDate: 2015
    name: Red Hat Certified System Administrator
    website: Red Hat,Inc.
interests:
  - name: "In my free time I enjoy going on bicycle rides with my riding club or my friends. Afterwards, I like to tinker with electronics and technology."
